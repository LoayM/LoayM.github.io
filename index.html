<!DOCTYPE html>
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="description" content="Loay Mualem's Homepage">
  <title>Loay Mualem</title>
  
  <!-- Favicon -->
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  
  <!-- External JS (if needed) -->
  <script type="text/javascript" src="js/hidebib.js"></script>
  <script src="js/scramble.js"></script>
  
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-154732200-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-154732200-1');
  </script>
</head>


<!-- =================== Bio =================== -->
<body>
<table width="1000" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
<tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <pageheading>Loay Mualem</pageheading><br>
    <font id="email" style="display:inline;">loaymua_at_gmail_dot_com</font>
  </p>

  <tr>
    <td width="32%" valign="top"><a href="images/loay.jpg"><img src="images/loay.jpg" width="100%" style="border-radius:15px"></a>
    <p align=center>
    <a href="files/CV.pdf">CV</a> |
    <a href="https://scholar.google.com/citations?user=kMWFvg4AAAAJ&hl=iw&oi=ao">Google Scholar</a> | 
    <a href="https://il.linkedin.com/in/loay-mualem">LinkedIn</a>|<br/> 
    </p>
    </td>
    <td width="68%" valign="top" align="justify">
    <p></p>
    <div style="font-size:12.5pt;" align="justify">
      <p>
        I am a last-year Computer Science Ph.D. candidate under the supervision of Prof. Moran Feldman, at the Computer Science Department, University of Haifa, and under the supervision of Prof. Dan Feldman,  at the Robotics & Big Data Labs, Computer Science Department, University of Haifa.


      </p>
      <p>
        My main research interests are Optimization, Machine/Deep Learning, and Big Data. I am passionate about employing provable optimization techniques to enhance the quality and accelerate the training of real-world Machine/Deep Learning models.

      </p>
    </div>
    </td>
  </tr>
</table>


<!-- =================== Experience =================== -->
<sectionheading>&nbsp;&nbsp;Experience</sectionheading>
<ul>
<table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
  <tr>

    <th width="16%" valign="top" align="center">
      <img src="images/dh2.png" alt="sym" width="50%"></a>
      <p style="line-height:1.3; font-size:12pt">DataHeroes<br>Lead DL + LLM Researcher<br>April 23 - Present</p>
    </th>
    <th width="16%" valign="top" align="center">
      <img src="images/hu.png" alt="sym" width="55%"></a>
      <p style="line-height:1.3; font-size:12pt">Haifa University<br>M.Sc. + Ph.D. in CS<br>&nbsp; Mar 18 - Mar 21, &nbsp;&nbsp;&nbsp; Oct 21 - Present</p>
    </th>
  </tr>
</table>
</ul>



<!-- =================== Teaching =================== -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
  <tr><td><sectionheading>&nbsp;&nbsp;Teaching @ University of Haifa</sectionheading></td></tr>
</table>
<table width="100%" align="top" border="0" cellpadding="0">
  <tr>
    <span style="line-height:0.7">
      <p style="text-align:left; padding-left:11px">
        2022-2024: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Lecturer, Introduction to Computer Science
      </p>
      <p style="text-align:left; padding-left:11px">
         2022-2024:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.Sc. final projects supervisor and mentor
      </p>
      <p style="text-align:left; padding-left:11px">
        2021-2023:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Lecturer, Introduction to Mathematics for first-year students
      </p>
      <p style="text-align:left; padding-left:11px">
        2017-2021:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Head TA, Introduction to Algorithms
      </p>
      <p style="text-align:left; padding-left:11px">
        2016-2017,2021-2022:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Head TA, Data Stuctures
      </p>
      <p style="text-align:left; padding-left:11px">
        2018-2021:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Head TA, Introduction to Compilers
      </p>
    </span>
  </tr>
</table>



<!-- =================== Preprints ===================

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

<tr><td><sectionheading>Preprints</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

</table> -->

<!-- ====================================================================  -->

<!-- =================== Publications =================== -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">

<tr><td><sectionheading>Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

<tr>
  <td width="33%" valign="top" align="center">
    <a href="#/"></a>
  </td>
  <td width="67%" valign="top">
    <p><a href="#" id="bridge">
        <heading>Bridging the Gap Between General and Down-Closed Convex Sets in Submodular Maximization</heading>
      </a><br>
      
      <b><u>Loay Mualem</b></u>, Murad Tukan, Moran Feldman
      <br>
      IJCAI 2024
    </p>

    <div class="paper" id="bridge">
     <a href="https://arxiv.org/abs/2310.17642">paper</a> |
      <a href="javascript:toggleblock('bridge_gap')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('bridge')" class="togglebib">bibtex</a> |
      <p align="justify"><i id="bridge_gap">Optimization of DR-submodular functions has experienced a notable surge in significance in recent times, marking a pivotal development within the domain of non-convex optimization. Motivated by real-world scenarios, some recent works have delved into the maximization of non-monotone DR-submodular functions over general (not necessarily down-closed) convex set constraints. Up to this point, these works have all used the minimum L-infinity norm of any feasible solution as a parameter. Unfortunately, a recent hardness result due to Mualem and Feldman shows that this approach cannot yield a smooth interpolation between down-closed and non-down-closed constraints. In this work, we suggest novel offline and online algorithms that provably provide such an interpolation based on a natural decomposition of the convex body constraint into two distinct convex bodies: a down-closed convex body and a general convex body. We also empirically demonstrate the superiority of our proposed algorithms across three offline and two online applications.
      </i></p>
<pre xml:space="preserve">
@article{mualem2024bridging,
  title={Bridging the Gap Between General and Down-Closed Convex Sets in Submodular Maximization},
  author={Mualem, Loay and Tukan, Murad and Fledman, Moran},
  journal={arXiv preprint arXiv:2401.09251},
  year={2024}
}

</pre>
</div>
</td>
</tr>



<tr>
    <td width="33%" valign="top" align="center">
      <a href="#/"></a>
    </td>
    <td width="67%" valign="top">
      <p><a href="#" id="Follow">
          <heading>Privacy Preserving Epigenetic PaceMaker: Stronger Privacy and Improved Efficiency</heading>
        </a><br>
        Meir Goldenberg,<b><u></u>Loay Mualem</b></u>, Amit Shahar, Sagi Snir, Adi Akavia
        <br>
        Genome Research
      </p>
  
      <div class="paper" id="privacy">
       <a href="https://www.biorxiv.org/content/biorxiv/early/2024/02/20/2024.02.15.580590.full.pdf">paper</a> |
        <a href="javascript:toggleblock('privacy_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('privacy')" class="togglebib">bibtex</a> |
        <p align="justify"><i id="privacy_abs">DNA methylation data plays a crucial role in estimating chronological age in mammals, offering real-time insights into an individual's aging process. The Epigenetic Pacemaker (EPM) model allows inference of the biological age as deviations from the population trend. Given the sensitivity of this data, it is essential to safeguard both inputs and outputs of the EPM model. In a recent study by Goldenberg et al., a privacy-preserving approach for EPM computation was introduced, utilizing Fully Homomorphic Encryption (FHE). However, their method had limitations, including having high communication complexity and being impractical for large datasets. Our work presents a new privacy preserving protocol for EPM computation, analytically improving both privacy and complexity. Notably, we employ a single server for the secure computation phase while ensuring privacy even in the event of server corruption (compared to requiring two non-colluding servers in Goldenberg et al). Using techniques from symbolic algebra and number theory, the new protocol eliminates the need for communication during secure computation, significantly improves asymptotic runtime and offers better compatibility to parallel computing for further time complexity reduction. We have implemented our protocol, demonstrating its ability to produce results similar to the standard (insecure) EPM model with substantial performance improvement compared to Goldenberg et al. These findings hold promise for enhancing data security in medical applications where personal privacy is paramount. The generality of both the new approach and the EPM, suggests that this protocol may be useful to other uses employing similar expectation maximization techniques.
        </i></p>
<pre xml:space="preserve">
  @inproceedings{goldenberg2024privacy,
    title={Privacy Preserving Epigenetic PaceMaker: Stronger Privacy and Improved Efficiency},
    author={Goldenberg, Meir and Mualem, Loay and Shahar, Amit and Snir, Sagi and Akavia, Adi},
    booktitle={International Conference on Research in Computational Molecular Biology},
    pages={412--416},
    year={2024},
    organization={Springer}
  }


</pre>
</div>
</td>
</tr>

<tr>
    <td width="33%" valign="top" align="center">
      <a href="#/"></a>
    </td>
    <td width="67%" valign="top">
      <p><a href="#" id="minmax">
          <heading>Submodular Minimax Optimization: Finding Effective Sets</heading>
        </a><br>
        <b><u>Loay Mualem</b></u>, Ethan R. Elenberg, Moran Feldman, Amin Karbasi
        <br>
        AISTATS 2024 
      </p>
  
      <div class="paper" id="onthesize">
       <a href="https://proceedings.mlr.press/v238/raed-mualem24a.html">paper</a> |
        <a href="javascript:toggleblock('minmax_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('onthesize')" class="togglebib">bibtex</a> 
        <p align="justify"><i id="minmax_abs">Despite the rich existing literature about minimax optimization in continuous settings, only very partial results of this kind have been obtained for combinatorial settings. In this paper, we fill this gap by providing a characterization of submodular minimax optimization, the problem of finding a set (for either the min or the max player) that is effective against every possible response. We show when and under what conditions we can find such sets. We also demonstrate how minimax submodular optimization provides robust solutions for downstream machine learning applications such as (i) prompt engineering in large language models, (ii) identifying robust waiting locations for ride-sharing, (iii) kernelization of the difficulty of instances of the last setting, and (iv) finding adversarial images. Our experiments show that our proposed algorithms consistently outperform other baselines.
        </i></p>
<pre xml:space="preserve">
  @inproceedings{mualem2024submodular,
    title={Submodular minimax optimization: Finding effective sets},
    author={Mualem, Loay Raed and Elenberg, Ethan R and Feldman, Moran and Karbasi, Amin},
    booktitle={International Conference on Artificial Intelligence and Statistics},
    pages={1081--1089},
    year={2024},
    organization={PMLR}
  }




</pre>
</div>
</td>
</tr>

<!-- ====================================================================  -->


<tr>
    <td width="33%" valign="top" align="center">
      <a href="#/"></a>
      <img src="images/subsetselect.png" alt="sym" width="100%" height="100%"
        style="border-radius:15px; opacity:1.0; filter:alpha(opacity=80);"></a>
    </td>
    <td width="67%" valign="top">
      <p><a href="#" id="Seubset">
          <heading>Resolving the Approximability of Offline and Online Non-monotone DR-Submodular Maximization over General Convex Sets</heading>
        </a><br>
        <b><u>Loay Mualem</b></u>, Moran Feldman
        <br>
        AISTATS 2023 
      </p>
  
      <div class="paper" id="resolving">
       <a href="https://proceedings.mlr.press/v206/mualem23a.html">paper</a> |
        <a href="javascript:toggleblock('resolving_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('resolving')" class="togglebib">bibtex</a> | 
        <p align="justify"><i id="resolving_abs">In recent years, maximization of DR-submodular continuous functions became an important research field, with many real-world applications in the domains of machine learning, communication systems, operation research, and economics. Most of the works in this field study maximization subject to down-closed convex set constraints due to an inapproximability result. However, Durr et al. showed that one can bypass this inapproximability by proving approximation ratios that are functions of $m$, the minimum $\ell_\infty$-norm of any feasible vector. Given this observation, it is possible to get results for maximizing a DR-submodular function subject to general convex set constraints, which has led to multiple works on this problem. The most recent of which is a polynomial time $\tfrac{1}{4}(1 - m)$-approximation offline algorithm due to Du. However, only a sub-exponential time $\tfrac{1}{3\sqrt{3}}(1 - m)$-approximation algorithm is known for the corresponding online problem. In this work, we present a polynomial time online algorithm matching the $\tfrac{1}{4}(1 - m)$-approximation of the state-of-the-art offline algorithm. We also present an inapproximability result showing that our online algorithm and Du's offline algorithm are both optimal in a strong sense. Finally, we study the empirical performance of our algorithm and the algorithm of Du (which was only theoretically studied previously), and show that they consistently outperform previously suggested algorithms on revenue maximization, location summarization, and quadratic programming applications.
        </i></p>
<pre xml:space="preserve">
  @inproceedings{mualem2023resolving,
    title={Resolving the approximability of offline and online non-monotone dr-submodular maximization over general convex sets},
    author={Mualem, Loay and Feldman, Moran},
    booktitle={International Conference on Artificial Intelligence and Statistics},
    pages={2542--2564},
    year={2023},
    organization={PMLR}
  }



</pre>
</div>
</td>
</tr>

<!-- ====================================================================  -->

<tr>
    <td width="33%" valign="top" align="center">
      <a href="#/"></a>
      <img src="images/autocor.png" alt="sym" width="100%" height="100%"
        style="border-radius:15px; opacity:1.0; filter:alpha(opacity=80);"></a>
    </td>
    <td width="67%" valign="top">
      <p><a href="#" id="using">
          <heading>Using Partial Monotonicity in Submodular Maximization</heading>
        </a><br>
        <b><u>Loay Mualem</b></u>, Moran Feldman
        <br>
        NeurIPS 2022 
      </p>
  
      <div class="paper" id="using">
       <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/1227a7a80529ecfe033065b9fcc5a042-Paper-Conference.pdf">paper</a> |
        <a href="javascript:toggleblock('using_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('using')" class="togglebib">bibtex</a> |
        <p align="justify"><i id="using_abs">Over the last two decades, submodular function maximization has been the workhorse of many discrete optimization problems in machine learning applications. Traditionally, the study of submodular functions was based on binary function properties, but recent works began to consider continuous function properties such as the submodularity ratio and the curvature. The monotonicity property of set functions plays a central role in submodular maximization. Nevertheless, no continuous version of this property has been suggested to date (as far as we know), which is unfortunate since submodular functions that are almost monotone often arise in machine learning applications. In this work, we fill this gap by defining the monotonicity ratio, which is a continuous version of the monotonicity property. We then show that for many standard submodular maximization algorithms one can prove new approximation guarantees that depend on the monotonicity ratio; leading to improved approximation ratios for the common machine learning applications of movie recommendation, quadratic programming, image summarization, and ride-share optimization.
          
        </i></p>
<pre xml:space="preserve">
  @article{mualem2022using,
    title={Using partial monotonicity in submodular maximization},
    author={Mualem, Loay and Feldman, Moran},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={2723--2736},
    year={2022}
  }


</pre>
</div>
</td>
</tr>


<!-- ====================================================================  -->

 <tr>
    <td width="33%" valign="top" align="center">
      <a href="#/"></a>
      <img src="images/prune.png" alt="sym" width="100%" height="100%"
        style="border-radius:15px; opacity:1.0; filter:alpha(opacity=80);"></a>
    </td>
    <td width="67%" valign="top">
      <p><a href="#" id="PRUNE">
          <heading>Pruning Neural Networks via Coresets and Convex Geometry: Towards No Assumptions</heading>
        </a><br>
          Murad Tukan, <u><b></b>Loay Mualem</b></u>, Alaa Maalouf
        <br>
        NeurIPS 2022 
      </p>
  
      <div class="paper" id="prune">
       <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/f7fc38fdd95fd146a471791b93ff9f12-Abstract-Conference.htmll">paper</a> |
        <a href="javascript:toggleblock('prune_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('prune')" class="togglebib">bibtex</a>    
        <p align="justify"><i id="prune_abs">Pruning is one of the predominant approaches for compressing deep neural networks (DNNs). Lately, coresets (provable data summarizations) were leveraged for pruning DNNs, adding the advantage of theoretical guarantees on the trade-off between the compression rate and the approximation error. However, coresets in this domain were either data dependant or generated under restrictive assumptions on both the model's weights and inputs. In real-world scenarios, such assumptions are rarely satisfied, limiting the applicability of coresets. To this end, we suggest a novel and robust framework for computing such coresets under mild assumptions on the model's weights and without any assumption on the training data. The idea is to compute the importance of each neuron in each layer with respect to the output of the following layer. This is achieved by an elegant combination of L\"{o}wner ellipsoid and Caratheodory theorem.Our method is simultaneously data-independent, applicable to various networks and datasets (due to the simplified assumptions), and theoretically supported. Experimental results show that our method outperforms existing coreset based neural pruning approaches across a wide range of networks and datasets. For example, our method achieved a 62% compression rate on ResNet50 on ImageNet with 1.09% drop in accuracy. 
        </i></p>
<pre xml:space="preserve">
@article{tukan2022pruning,
  title={Pruning neural networks via coresets and 
         convex geometry: Towards no assumptions},
  author={Tukan, Murad and Mualem, Loay and Maalouf, Alaa},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38003--38019},
  year={2022}
}


</pre>
</div>
</td>
</tr>

<!-- ====================================================================  -->

   <tr>
    <td width="33%" valign="top" align="center">
      <a href="#/"></a>
      <img src="images/cosinefit.png" alt="sym" width="80%" height="28.5%"
        style="border-radius:15px; opacity:1.0; filter:alpha(opacity=80);"></a>
    </td>
    <td width="67%" valign="top">
      <p><a href="#" id="COSINEFIT">
          <heading>Online Bin Packing of Squares and Cubes </heading>
        </a><br>
        Leah Epstein, <u><b>Loay Mualem</b></u>
        <br>
        Algorithmica 
      </p>
  
      <div class="paper" id="packing">
       <a href="https://link.springer.com/article/10.1007/s00453-022-01078-9">paper</a> |
        <a href="javascript:toggleblock('packing_abs')">abstract</a> |
        <a shape="rect" href="javascript:togglebib('packing')" class="togglebib">bibtex</a> |    
        <p align="justify"><i id="packing_abs">In the d-dimensional online bin packing problem, d-dimensional cubes of positive sizes no larger than 1 are presented one by one to be assigned to positions in d-dimensional unit cube bins. In this work, we provide improved upper bounds on the asymptotic competitive ratio for square and cube bin packing problems, where our bounds do not exceed 2.0885 and 2.5735 for square and cube packing, respectively. To achieve these results, we adapt and improve a previously designed harmonic-type algorithm, and apply a different method for defining weight functions. We detect deficiencies in the state-of-the-art results by providing counter-examples to the current best algorithms and their analysis, where the claimed bounds were 2.1187 for square packing and 2.6161 for cube packing.
        </i></p>
<pre xml:space="preserve">
  @article{epstein2023online,
    title={Online bin packing of squares and cubes},
    author={Epstein, Leah and Mualem, Loay},
    journal={Algorithmica},
    volume={85},
    number={5},
    pages={1415--1458},
    year={2023},
    publisher={Springer}
  }



<!-- =================== Footnote =================== -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td><br><p align="right"><font size="2">
    A huge thanks to template from <a href="https://people.eecs.berkeley.edu/~pathak/">this</a>.
  </font></p></td></tr>
</table>

</td></tr>


<script xml:space="preserve" language="JavaScript">
  hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('bridge');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('privacy_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('packing_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('prune_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('using_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('resolving_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('minmax_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('privacy_abs');
</script>


</body>

</html>
